{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C964 - Randeep Jalli\n",
    "## Vehicle Price prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pandas_instance\n",
    "    import seaborn as seaborn_instance\n",
    "    import matplotlib.pyplot as pyplot_instance\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import ipysheet\n",
    "    import ipywidgets\n",
    "except SyntaxError:\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "_________________\n",
    "\n",
    "## Data Ingest\n",
    "\n",
    "\n",
    "To begin with we ingest our data from the comma-separated value file included with this project.\n",
    "A few rows and columns are included below for reference.\n",
    "\n",
    "_________________"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame= pandas_instance.read_csv('data/car data.csv')\n",
    "dataFrame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "\n",
    "Let's see what the shape of the dataset is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "In order to clean the dataset, we replace values with equivalents that are already reflected elsewhere in the data.\n",
    "\n",
    "\n",
    "\n",
    "_________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataFrame['Seller_Type'].replace(['Ebay Motors Merchant'], 'Dealer')\n",
    "dataFrame['Transmission'].replace(['6-Speed'], 'Manual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "Below we can see all the different unique feature types available in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "_________________\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feature in ['Fuel_Type', 'Seller_Type', 'Transmission', 'Owner']:\n",
    "    print(\"__________________________________________________________________________________________________\")\n",
    "    print(\"Feature Type: \" + feature)\n",
    "    print(\"Unique Values: \" + str(dataFrame[feature].unique()))\n",
    "    print(\"__________________________________________________________________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "_________________\n",
    "\n",
    "Check for a Dataset clear of null or \"Invalid/NotANumber\" data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "The Dataframe we created is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "## Data Cleaning\n",
    "In order to predict the final price we need to select only the columns we want to be in our new DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_dataset=dataFrame[['Year','Selling_Price','Present_Price','Kms_Driven','Fuel_Type','Seller_Type','Transmission','Owner']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "In order to reflect the age of the car, we need to create a custom column and subtract from the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_dataset['Current_Year']=2020\n",
    "cleaned_dataset['age']=cleaned_dataset['Current_Year']-cleaned_dataset['Year']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of the rows from our cleaned DataSet that now includes the age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the current year from our DataSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.drop(['Year','Current_Year'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "## Data Encoding\n",
    "\n",
    "In order to allow the model to predict the value of the categorical features, we perform a \"hot encoding\" and change the categorical values to numbers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset= pandas_instance.get_dummies(cleaned_dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "A sample of the rows from our encoded DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Sampled Columns\n",
    "A sample of the columns from our encoded DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset.corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Pair Plot\n",
    "\n",
    "\n",
    "Below we see a Pair Plot, showing various correlative measures of our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = seaborn_instance.pairplot(cleaned_dataset).fig.suptitle('Pair Plot of Columns and Correlations', fontsize=50, weight='bold', y=1.1)\n",
    "#air_plot.fig.subplots_adjust(top=0.9)\n",
    "#pair_plot.fig.suptitle('Title', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "## Heatmap\n",
    "\n",
    "In this Heatmap the Yellow features have little correlation to increased selling price, the Blue features have a high correlation to increased selling price.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "correlation_matrix = cleaned_dataset.corr()\n",
    "top_features = correlation_matrix.index\n",
    "pyplot_instance.figure(figsize=(20,20))\n",
    "heatmap=seaborn_instance.heatmap(cleaned_dataset[top_features].corr() ,annot=True, cmap=\"YlGnBu\").set_title('Heatmap Of Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "## Data Seperation\n",
    "\n",
    "Below we separate our dataset into depended and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent and Dependent features\n",
    "dependentFeature= cleaned_dataset.iloc[:,1:]\n",
    "independentFeature= cleaned_dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "_________________"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependentFeature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#independentFeature.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "## Feature Analysis\n",
    "\n",
    "We create a Extra-Tree's regressor that implements a set of randomized decision tree's to show the importance of the various features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(dependentFeature,independentFeature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.feature_importances_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "_________________\n",
    "\n",
    "## Important Features\n",
    "Below we can see a graph of the various important features and a list of the top 5 most correlated features to selling price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importantFeatures= pandas_instance.Series(model.feature_importances_, index=dependentFeature.columns)\n",
    "importantFeatures.nlargest(5).plot(kind='barh')\n",
    "pyplot_instance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "In order to gather enough data for testing the model, we split the dataset into 80% train and 20% test data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test, y_train,y_test= train_test_split(dependentFeature,independentFeature,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "Below we can see the main logic of the model, the Linear Regression function is called to create a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "simple_regression= LinearRegression()\n",
    "\n",
    "simple_regression.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We create a prediction from the trained model using the test data we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= simple_regression.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "We show an overlay distribution plot of the delta between the test dataset and the predited dataset.\n",
    "This represents the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn_instance.distplot(y_test-y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error = r2_score(y_test, y_pred)\n",
    "print(\"Accuracy: \" + str(round(error*100,2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "_________________\n",
    "\n",
    "\n",
    "\n",
    "# Intelligent Vehicle Price Predictor\n",
    "## Calculator\n",
    "\n",
    "Below we have our Selling Price Prediction Calculator.\n",
    "This Calculator allows the user to predict the selling price of their car by tweaking the value for various features.\n",
    "In order to predict the selling price for a car, please change a value in one of the fields and press enter.\n",
    "The Final Price value will auto populate. Please note you MUST use the units that are noted in the feilds below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sheet = ipysheet.sheet(rows=8, columns=2, column_headers=False, row_headers=False)\n",
    "present_price = ipysheet.cell(0, 1, 4.2, label_left='Present Price in Ten Thousand Dollar Increments, i.e 4.2 is $42000', type='numeric')\n",
    "Kms_Driven = ipysheet.cell(1, 1, 10000, label_left='Kilometers Driven ', type='numeric')\n",
    "Owner = ipysheet.cell(2, 1, 3, label_left='Number of Previous Owners in Integer, i.e 1 is 1 Previous Owner', type='numeric')\n",
    "age = ipysheet.cell(3, 1, 3, label_left='Number of Years Old in Integer, i.e 1 is 1 year old', type='numeric')\n",
    "fuel_type = ipysheet.cell(4, 1, 0, label_left='Fuel Type ( use 1 for Diesel 0 for Gasoline)', type='numeric')\n",
    "seller_type = ipysheet.cell(5, 1, 0, label_left='Fuel Type ( use 1 for Individual 0 for Other)', type='numeric')\n",
    "transmission_type = ipysheet.cell(6, 1, 1, label_left='Gearbox Type ( use 1 for Manual 0 for Automatic)', type='numeric')\n",
    "price = ipysheet.cell(7, 1, 51565.26, label_left='Final Price', read_only=True)\n",
    "\n",
    "\n",
    "\n",
    "def calculate(change):\n",
    "    tempdata = {'Present_price': [present_price.value],\n",
    "        'Kms_Driven': [Kms_Driven.value],\n",
    "        'Owner': [Owner.value],\n",
    "        'age': [age.value],\n",
    "        'Seller_Type_Individual': [seller_type.value],\n",
    "        'Transmission_Manual': [transmission_type.value]}\n",
    "    if fuel_type.value == 1:\n",
    "        tempdata['Fuel_Type_Diesel'] = [1]\n",
    "        tempdata['Fuel_Type_Petrol'] = [0]\n",
    "    elif fuel_type.value == 0:\n",
    "        tempdata['Fuel_Type_Diesel'] = [0]\n",
    "        tempdata['Fuel_Type_Petrol'] = [1]\n",
    "    simple_regression.fit(X_train,y_train)\n",
    "    temp_test = pandas_instance.DataFrame.from_dict(tempdata)\n",
    "    temp_pred = simple_regression.predict(temp_test)\n",
    "    price.value = round(temp_pred[0] * 10000, 2)\n",
    "\n",
    "present_price.observe(calculate, 'value')\n",
    "Kms_Driven.observe(calculate, 'value')\n",
    "Owner.observe(calculate, 'value')\n",
    "age.observe(calculate, 'value')\n",
    "fuel_type.observe(calculate, 'value')\n",
    "seller_type.observe(calculate, 'value')\n",
    "transmission_type.observe(calculate, 'value')\n",
    "\n",
    "ipywidgets.VBox([sheet])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}